{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shouvikcirca/PCB_Defect_Detection/blob/master/LeNet5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXw93V3KBuGL"
   },
   "source": [
    "# LeNet5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x42ZnnA0BuGM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "JC2jsHuXB2q6",
    "outputId": "dfcfaef2-d198-4066-ba13-15707c384c17"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoSCktJAB60c"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# X = np.load('drive/My Drive/Copy of xtrain.npy')\n",
    "# y = np.load('drive/My Drive/Copy of ytrain.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local machine\n",
    "X_train = pickle.load(open(f'xtrain298.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'ytrain298.pkl', 'rb'))\n",
    "X_test = pickle.load(open(f'xtest298.pkl', 'rb'))\n",
    "y_test = pickle.load(open(f'ytest298.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q1zTL2ONB9Lw",
    "outputId": "37bc1812-d9fe-4334-9998-d17f11e3564c"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# X = torch.from_numpy(X)\n",
    "# X = X.permute(0,3,1,2)\n",
    "# y = torch.from_numpy(y)\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLB5FrOMBuGR"
   },
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUC_1EbfBuGS"
   },
   "outputs": [],
   "source": [
    "def getNormalized(X,s):\n",
    "    flattened_channels = X.reshape(3,-1)\n",
    "    channel_mean = flattened_channels.mean(dim = 1)\n",
    "    channel_stddev = flattened_channels.std(dim = 1)\n",
    "    preprocess2 = transforms.Compose([\n",
    "                      transforms.Normalize(channel_mean, channel_stddev)\n",
    "    ])\n",
    "\n",
    "\n",
    "    temptwo = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess2(X[i])\n",
    "        temptwo = torch.cat([temptwo, a.reshape(1,3,s,s)])\n",
    "  \n",
    "    return temptwo\n",
    "\n",
    "\n",
    "def imageSetResize(newSize,X):\n",
    "    preprocess1 = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize(newSize),\n",
    "                        transforms.ToTensor()])\n",
    "  \n",
    "    temp = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess1(X[i])\n",
    "        temp = torch.cat([temp, a.reshape(1,3,newSize,newSize)])\n",
    "\n",
    "    return temp \n",
    "\n",
    "\n",
    "def splitTrainTest(X,y):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    ul = math.floor(0.8*X.shape[0])\n",
    "    train_indices = shuffled_indices[:ul]\n",
    "    test_indices = shuffled_indices[ul:]\n",
    "    # train_indices.shape[0] + test_indices.shape[0]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]  \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "    print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def labelize(p):\n",
    "    labelized_preds = []\n",
    "    for i in p:\n",
    "        l = 0. if i[0]>i[1] else 1.\n",
    "        labelized_preds.append(l)\n",
    "\n",
    "    return torch.tensor(labelized_preds)\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_and_batch(X,y,num,bs):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    newX = X[shuffled_indices]\n",
    "    newY = y[shuffled_indices]\n",
    "\n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    for i in range(num):\n",
    "        X_batches.append(X[i*bs:(i+1)*bs])\n",
    "        y_batches.append(y_train[i*bs:(i+1)*bs])\n",
    "\n",
    "    return X_batches, y_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qj6jcCXLBuGW"
   },
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQy8vua7BuGX"
   },
   "outputs": [],
   "source": [
    "pars = []\n",
    "\n",
    "\n",
    "#C1\n",
    "c1 = nn.Conv2d(3,6, kernel_size = 5)\n",
    "pars = pars + list(c1.parameters())\n",
    "\n",
    "#S2\n",
    "pool1 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "#C3\n",
    "first_cons6_filterlist = []\n",
    "second_cons6_filterlist = []\n",
    "third_cons3_filterlist = []\n",
    "fourth_last1_filterlist = []\n",
    "for i in range(6):\n",
    "    first_cons6_filterlist.append(nn.Conv2d(3,1,kernel_size = 5))\n",
    "    pars = pars + list(first_cons6_filterlist[-1].parameters())\n",
    "    \n",
    "for i in range(6):\n",
    "    second_cons6_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "    pars = pars + list(second_cons6_filterlist[-1].parameters())\n",
    "    \n",
    "for i in range(3):\n",
    "    third_cons3_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "    pars = pars + list(third_cons3_filterlist[-1].parameters())\n",
    "\n",
    "fourth_last1_filterlist = [nn.Conv2d(6,1,kernel_size = 5)]\n",
    "pars = pars + list(fourth_last1_filterlist[-1].parameters())\n",
    "\n",
    "#S4\n",
    "pool2 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "#C5\n",
    "conv3 = nn.Conv2d(16, 120, kernel_size = 5)\n",
    "pars = pars + list(conv3.parameters())\n",
    "\n",
    "#F6\n",
    "ll1 = nn.Linear(120, 84)\n",
    "\n",
    "#F7\n",
    "ll2 = nn.Linear(84,2)\n",
    "pars = pars + list(ll1.parameters()) + list(ll2.parameters())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmnhG202loT5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5QbXFhbBuGa"
   },
   "outputs": [],
   "source": [
    "# def displayDetails(lone = None, ltwo=None):\n",
    "#     if lone is not None:\n",
    "#         a = lone\n",
    "#         print('--------')\n",
    "#         for i in a[0]:\n",
    "#             print(i)\n",
    "#         print('--------')\n",
    "#         for i in a[1]:\n",
    "#             print(i)\n",
    "#         print('-------')\n",
    "#         for i in a[2]:\n",
    "#             print(i)\n",
    "#         print('-------')\n",
    "#         for i in a[3]:\n",
    "#             print(i)\n",
    "#     if ltwo is not None:\n",
    "#         a = ltwo\n",
    "#         for i in a:\n",
    "#             print('-----')\n",
    "#             for j in i:\n",
    "#                 print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2xDzuPRBuGe"
   },
   "outputs": [],
   "source": [
    "# displayDetails(lone = [first_cons6_filterlist,second_cons6_filterlist,third_cons3_filterlist,fourth_last1_filterlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-jMzvZ1BuGh"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DC6H9PuXBuGi"
   },
   "outputs": [],
   "source": [
    "# resized_imageset = imageSetResize(32, X.float())\n",
    "# normalized_imageset = getNormalized(resized_imageset.float(),32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "U5d3IZAnDsfO",
    "outputId": "6f4c9667-7c45-4e9f-dd43-fe5e1a7bdf3c"
   },
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = splitTrainTest(resized_imageset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(X_train, open(\"xtrain298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(X_test, open(\"xtest298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(y_train, open(\"ytrain298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(y_test, open(\"ytest298.pkl\", 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpmIw5uaBuGl"
   },
   "outputs": [],
   "source": [
    "def ef(li, c1_out):\n",
    "    return torch.index_select(c1_out, 1, torch.tensor(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train -> [0]:119 [1]:119\n",
      "y_test -> [0]:30 [1]:30\n"
     ]
    }
   ],
   "source": [
    "print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdR1kcwSBuGp"
   },
   "outputs": [],
   "source": [
    "def feedForward(X):\n",
    "    \n",
    "    global c1\n",
    "    global first_cons6_filterlist\n",
    "    global second_cons6_filterlist\n",
    "    global third_cons3_filterlist\n",
    "    global fourth_last1_filterlist\n",
    "    nos = X.shape[0]\n",
    "    c1_out = c1(X)\n",
    "    out = torch.tanh(pool1(c1_out))\n",
    "    lione = [ef([0,1,2],out),ef([1,2,3],out), ef([2,3,4],out), ef([3,4,5],out), ef([0,4,5],out),ef([0,1,5],out)]\n",
    "    litwo = [ef([0,1,2,3],out),ef([1,2,3,4],out), ef([2,3,4,5],out), ef([0,3,4,5],out), ef([0,1,4,5],out),ef([0,1,2,5],out)]\n",
    "    lithree = [ef([0,1,3,4],out),ef([1,2,4,5],out), ef([0,2,3,5],out)]\n",
    "    lifour = [ef([0,1,2,3,4,5],out)]\n",
    "    feature_maps1 = []\n",
    "    feature_maps2 = []\n",
    "    feature_maps3 = []\n",
    "    feature_maps4 = []\n",
    "    for i in range(6):\n",
    "        feature_maps1.append(first_cons6_filterlist[i](lione[i]))\n",
    "    for i in range(6):\n",
    "        feature_maps2.append(second_cons6_filterlist[i](litwo[i]))\n",
    "    for i in range(3):\n",
    "        feature_maps3.append(third_cons3_filterlist[i](lithree[i]))\n",
    "    for i in range(1):\n",
    "        feature_maps4.append(fourth_last1_filterlist[i](lifour[i]))\n",
    "    fms = []\n",
    "    fms.extend(feature_maps1)\n",
    "    fms.extend(feature_maps2)\n",
    "    fms.extend(feature_maps3)\n",
    "    fms.extend(feature_maps4)\n",
    "    tfms = torch.Tensor([])\n",
    "    for i in fms:\n",
    "        tfms = torch.cat([tfms, i], dim=1)\n",
    "    c2_out = torch.tanh(pool2(tfms))\n",
    "    c3_out = conv3(c2_out)\n",
    "    c3_out = c3_out.reshape(nos,120)\n",
    "    ll1_out = torch.tanh(ll1(c3_out))\n",
    "    ll2_out = ll2(ll1_out)\n",
    "    preds = nn.Softmax(dim=1)(ll2_out)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tDMvGyz7BuGs",
    "outputId": "d986b8d5-fe35-49c7-ef87-6bfe2d4de5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "TrainLoss:0.6902676820755005 TrainAccuracy:0.5  TestLoss:0.6920586228370667 TestAccuracy:0.5\n",
      "Epoch 1\n",
      "TrainLoss:0.685481071472168 TrainAccuracy:0.6218487394957983  TestLoss:0.6897379159927368 TestAccuracy:0.6\n",
      "Epoch 2\n",
      "TrainLoss:0.6769767999649048 TrainAccuracy:0.6218487394957983  TestLoss:0.6865504384040833 TestAccuracy:0.5333333333333333\n",
      "Epoch 3\n",
      "TrainLoss:0.6602924466133118 TrainAccuracy:0.6176470588235294  TestLoss:0.6792013049125671 TestAccuracy:0.6\n",
      "Epoch 4\n",
      "TrainLoss:0.6393295526504517 TrainAccuracy:0.634453781512605  TestLoss:0.6724849939346313 TestAccuracy:0.5833333333333334\n",
      "Epoch 5\n",
      "TrainLoss:0.6189413666725159 TrainAccuracy:0.6470588235294118  TestLoss:0.6671918034553528 TestAccuracy:0.6\n",
      "Epoch 6\n",
      "TrainLoss:0.5985246896743774 TrainAccuracy:0.7016806722689075  TestLoss:0.6607180237770081 TestAccuracy:0.55\n",
      "Epoch 7\n",
      "TrainLoss:0.5782433748245239 TrainAccuracy:0.7226890756302521  TestLoss:0.6509877443313599 TestAccuracy:0.6166666666666667\n",
      "Epoch 8\n",
      "TrainLoss:0.563955545425415 TrainAccuracy:0.7605042016806722  TestLoss:0.6436830163002014 TestAccuracy:0.65\n",
      "Epoch 9\n",
      "TrainLoss:0.5512613654136658 TrainAccuracy:0.7647058823529411  TestLoss:0.6315389275550842 TestAccuracy:0.7\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(pars,lr=1e-3) # Optimizer\n",
    "# tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    X_batches, y_batches = shuffle_and_batch(X_train, y_train, 4, 67)\n",
    "    for i in range(len(X_batches)):\n",
    "        preds = feedForward(X_batches[i])\n",
    "        loss = criterion(preds,y_batches[i].long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Checking model on training set\n",
    "    train_preds = feedForward(X_train)\n",
    "    train_loss = criterion(train_preds, y_train.long())\n",
    "    train_preds = labelize(train_preds)\n",
    "    train_prediction_comparisons = (y_train == train_preds)\n",
    "    train_accuracy = float(train_prediction_comparisons.sum())/float(y_train.shape[0])\n",
    "    print('TrainLoss:{} TrainAccuracy:{}'.format(train_loss.item(), train_accuracy), end='  ')\n",
    "  \n",
    "    # Checking model on testing set\n",
    "    test_preds = feedForward(X_test)\n",
    "    test_loss = criterion(test_preds, y_test.long())\n",
    "    test_preds = labelize(test_preds)\n",
    "    test_prediction_comparisons = (y_test == test_preds)\n",
    "    test_accuracy = float(test_prediction_comparisons.sum())/float(y_test.shape[0])\n",
    "    print('TestLoss:{} TestAccuracy:{}'.format(test_loss.item(), test_accuracy))\n",
    "    \n",
    "#     tb.add_scalar('TrainLoss',train_loss, epoch)\n",
    "#     tb.add_scalar('TestLoss',test_loss, epoch)\n",
    "#     tb.add_scalar('TrainAccuracy', train_accuracy, epoch)\n",
    "#     tb.add_scalar('TestAccuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcOnFXPuN8Oo"
   },
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmatrix(target,preds):\n",
    "\n",
    "    di = {}\n",
    "    \n",
    "    count00 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==0.0 and j==0.0:\n",
    "            count00+=1\n",
    "    di['count00'] = count00\n",
    "        \n",
    "    \n",
    "    count11 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==1. and j==1.:\n",
    "            count11+=1\n",
    "    di['count11'] = count11\n",
    "\n",
    "    \n",
    "    count01 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==0. and j==1.:\n",
    "            count01+=1\n",
    "    di['count01'] = count01\n",
    "    \n",
    "    count10 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==1. and j==0.:\n",
    "            count10+=1\n",
    "    di['count10'] = count10\n",
    "        \n",
    "    print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count00': 105, 'count11': 77, 'count01': 14, 'count10': 42}\n"
     ]
    }
   ],
   "source": [
    "cmatrix(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  14],\n",
       "       [ 42,  77]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, train_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LeNet5.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
