{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shouvikcirca/PCB_Defect_Detection/blob/master/LeNet5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXw93V3KBuGL"
   },
   "source": [
    "# LeNet5.3_BatchNorm_ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x42ZnnA0BuGM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "JC2jsHuXB2q6",
    "outputId": "dfcfaef2-d198-4066-ba13-15707c384c17"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoSCktJAB60c"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# X = np.load('drive/My Drive/Copy of xtrain.npy')\n",
    "# y = np.load('drive/My Drive/Copy of ytrain.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local machine\n",
    "X_train = pickle.load(open(f'X_train298.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'y_train298.pkl', 'rb'))\n",
    "X_test = pickle.load(open(f'X_test298.pkl', 'rb'))\n",
    "y_test = pickle.load(open(f'y_test298.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 3, 300, 300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q1zTL2ONB9Lw",
    "outputId": "37bc1812-d9fe-4334-9998-d17f11e3564c"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# X = torch.from_numpy(X)\n",
    "# X = X.permute(0,3,1,2)\n",
    "# y = torch.from_numpy(y)\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLB5FrOMBuGR"
   },
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUC_1EbfBuGS"
   },
   "outputs": [],
   "source": [
    "def getNormalized(X,s):\n",
    "    flattened_channels = X.reshape(3,-1)\n",
    "    channel_mean = flattened_channels.mean(dim = 1)\n",
    "    channel_stddev = flattened_channels.std(dim = 1)\n",
    "    preprocess2 = transforms.Compose([\n",
    "                      transforms.Normalize(channel_mean, channel_stddev)\n",
    "    ])\n",
    "\n",
    "\n",
    "    temptwo = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess2(X[i])\n",
    "        temptwo = torch.cat([temptwo, a.reshape(1,3,s,s)])\n",
    "  \n",
    "    return temptwo\n",
    "\n",
    "\n",
    "def imageSetResize(newSize,X):\n",
    "    preprocess1 = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize(newSize),\n",
    "                        transforms.ToTensor()])\n",
    "  \n",
    "    temp = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess1(X[i])\n",
    "        temp = torch.cat([temp, a.reshape(1,3,newSize,newSize)])\n",
    "\n",
    "    return temp \n",
    "\n",
    "\n",
    "def splitTrainTest(X,y):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    ul = math.floor(0.8*X.shape[0])\n",
    "    train_indices = shuffled_indices[:ul]\n",
    "    test_indices = shuffled_indices[ul:]\n",
    "    # train_indices.shape[0] + test_indices.shape[0]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]  \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "    print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def labelize(p):\n",
    "    labelized_preds = []\n",
    "    for i in p:\n",
    "        l = 0. if i[0]>i[1] else 1.\n",
    "        labelized_preds.append(l)\n",
    "\n",
    "    return torch.tensor(labelized_preds)\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_and_batch(X,y,num,bs):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    newX = X[shuffled_indices]\n",
    "    newY = y[shuffled_indices]\n",
    "\n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    for i in range(num):\n",
    "        X_batches.append(X[i*bs:(i+1)*bs])\n",
    "        y_batches.append(y_train[i*bs:(i+1)*bs])\n",
    "\n",
    "    return X_batches, y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 32\n",
    "X_train = imageSetResize(imsize, X_train.float())\n",
    "X_train = getNormalized(X_train.float(),imsize)\n",
    "X_test = imageSetResize(imsize, X_test.float())\n",
    "X_test = getNormalized(X_test.float(),imsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qj6jcCXLBuGW"
   },
   "source": [
    "Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQy8vua7BuGX"
   },
   "outputs": [],
   "source": [
    "pars = []\n",
    "\n",
    "\n",
    "#C1\n",
    "c1 = nn.Conv2d(3,6, kernel_size = 5)\n",
    "pars = pars + list(c1.parameters())\n",
    "\n",
    "#S2\n",
    "pool1 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "# BN1\n",
    "bn1 = nn.BatchNorm2d(6)\n",
    "pars = pars + list(bn1.parameters())\n",
    "\n",
    "#C3\n",
    "first_cons6_filterlist = []\n",
    "second_cons6_filterlist = []\n",
    "third_cons3_filterlist = []\n",
    "fourth_last1_filterlist = []\n",
    "for i in range(6):\n",
    "    first_cons6_filterlist.append(nn.Conv2d(3,1,kernel_size = 5))\n",
    "    pars = pars + list(first_cons6_filterlist[-1].parameters())\n",
    "    \n",
    "for i in range(6):\n",
    "    second_cons6_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "    pars = pars + list(second_cons6_filterlist[-1].parameters())\n",
    "    \n",
    "for i in range(3):\n",
    "    third_cons3_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "    pars = pars + list(third_cons3_filterlist[-1].parameters())\n",
    "\n",
    "fourth_last1_filterlist = [nn.Conv2d(6,1,kernel_size = 5)]\n",
    "pars = pars + list(fourth_last1_filterlist[-1].parameters())\n",
    "\n",
    "#S4\n",
    "pool2 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "\n",
    "#BN2\n",
    "bn2 = nn.BatchNorm2d(16)\n",
    "pars = pars + list(bn2.parameters())\n",
    "\n",
    "\n",
    "#C5\n",
    "conv3 = nn.Conv2d(16, 120, kernel_size = 5)\n",
    "pars = pars + list(conv3.parameters())\n",
    "\n",
    "\n",
    "#BN3\n",
    "bn3= nn.BatchNorm2d(120)\n",
    "pars = pars + list(bn3.parameters())\n",
    "\n",
    "\n",
    "#F6\n",
    "ll1 = nn.Linear(120, 84)\n",
    "\n",
    "\n",
    "#F7\n",
    "ll2 = nn.Linear(84,2)\n",
    "pars = pars + list(ll1.parameters()) + list(ll2.parameters())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmnhG202loT5"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# criterion = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5QbXFhbBuGa"
   },
   "outputs": [],
   "source": [
    "# def displayDetails(lone = None, ltwo=None):\n",
    "#     if lone is not None:\n",
    "#         a = lone\n",
    "#         print('--------')\n",
    "#         for i in a[0]:\n",
    "#             print(i)\n",
    "#         print('--------')\n",
    "#         for i in a[1]:\n",
    "#             print(i)\n",
    "#         print('-------')\n",
    "#         for i in a[2]:\n",
    "#             print(i)\n",
    "#         print('-------')\n",
    "#         for i in a[3]:\n",
    "#             print(i)\n",
    "#     if ltwo is not None:\n",
    "#         a = ltwo\n",
    "#         for i in a:\n",
    "#             print('-----')\n",
    "#             for j in i:\n",
    "#                 print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2xDzuPRBuGe"
   },
   "outputs": [],
   "source": [
    "# displayDetails(lone = [first_cons6_filterlist,second_cons6_filterlist,third_cons3_filterlist,fourth_last1_filterlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-jMzvZ1BuGh"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DC6H9PuXBuGi"
   },
   "outputs": [],
   "source": [
    "# resized_imageset = imageSetResize(32, X.float())\n",
    "# normalized_imageset = getNormalized(resized_imageset.float(),32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "U5d3IZAnDsfO",
    "outputId": "6f4c9667-7c45-4e9f-dd43-fe5e1a7bdf3c"
   },
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = splitTrainTest(resized_imageset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(X_train, open(\"xtrain298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(X_test, open(\"xtest298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(y_train, open(\"ytrain298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(y_test, open(\"ytest298.pkl\", 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpmIw5uaBuGl"
   },
   "outputs": [],
   "source": [
    "def ef(li, c1_out):\n",
    "    return torch.index_select(c1_out, 1, torch.tensor(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train -> [0]:119 [1]:119\n",
      "y_test -> [0]:30 [1]:30\n"
     ]
    }
   ],
   "source": [
    "print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdR1kcwSBuGp"
   },
   "outputs": [],
   "source": [
    "def feedForward(X):\n",
    "    \n",
    "    global c1\n",
    "    global first_cons6_filterlist\n",
    "    global second_cons6_filterlist\n",
    "    global third_cons3_filterlist\n",
    "    global fourth_last1_filterlist\n",
    "    nos = X.shape[0]\n",
    "    c1_out = c1(X)\n",
    "    out = F.relu(bn1(pool1(c1_out)))\n",
    "    lione = [ef([0,1,2],out),ef([1,2,3],out), ef([2,3,4],out), ef([3,4,5],out), ef([0,4,5],out),ef([0,1,5],out)]\n",
    "    litwo = [ef([0,1,2,3],out),ef([1,2,3,4],out), ef([2,3,4,5],out), ef([0,3,4,5],out), ef([0,1,4,5],out),ef([0,1,2,5],out)]\n",
    "    lithree = [ef([0,1,3,4],out),ef([1,2,4,5],out), ef([0,2,3,5],out)]\n",
    "    lifour = [ef([0,1,2,3,4,5],out)]\n",
    "    feature_maps1 = []\n",
    "    feature_maps2 = []\n",
    "    feature_maps3 = []\n",
    "    feature_maps4 = []\n",
    "    for i in range(6):\n",
    "        feature_maps1.append(first_cons6_filterlist[i](lione[i]))\n",
    "    for i in range(6):\n",
    "        feature_maps2.append(second_cons6_filterlist[i](litwo[i]))\n",
    "    for i in range(3):\n",
    "        feature_maps3.append(third_cons3_filterlist[i](lithree[i]))\n",
    "    for i in range(1):\n",
    "        feature_maps4.append(fourth_last1_filterlist[i](lifour[i]))\n",
    "    fms = []\n",
    "    fms.extend(feature_maps1)\n",
    "    fms.extend(feature_maps2)\n",
    "    fms.extend(feature_maps3)\n",
    "    fms.extend(feature_maps4)\n",
    "    tfms = torch.Tensor([])\n",
    "    for i in fms:\n",
    "        tfms = torch.cat([tfms, i], dim=1)\n",
    "    c2_out = F.relu(bn2(pool2(tfms)))\n",
    "    c3_out = bn3(conv3(c2_out))\n",
    "    c3_out = c3_out.reshape(nos,120)\n",
    "    ll1_out = F.relu(ll1(c3_out))\n",
    "    ll2_out = ll2(ll1_out)\n",
    "    preds = nn.Softmax(dim=1)(ll2_out)\n",
    "#     preds = F.log_softmax(ll2_out, dim=1)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelToOneHot(x):\n",
    "    t = torch.zeros(x.shape[0],2).float()\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i] == 0.:\n",
    "            t[i][0] = 1\n",
    "        else:\n",
    "            t[i][1] = 1\n",
    "            \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tDMvGyz7BuGs",
    "outputId": "d986b8d5-fe35-49c7-ef87-6bfe2d4de5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "TrainLoss:0.6769866347312927 TrainAccuracy:0.6134453781512605  TestLoss:0.6847366690635681 TestAccuracy:0.6666666666666666\n",
      "Epoch 1\n",
      "TrainLoss:0.6723993420600891 TrainAccuracy:0.634453781512605  TestLoss:0.6820648908615112 TestAccuracy:0.65\n",
      "Epoch 2\n",
      "TrainLoss:0.6683420538902283 TrainAccuracy:0.6722689075630253  TestLoss:0.6794629693031311 TestAccuracy:0.6666666666666666\n",
      "Epoch 3\n",
      "TrainLoss:0.6646751165390015 TrainAccuracy:0.7142857142857143  TestLoss:0.6768797636032104 TestAccuracy:0.6666666666666666\n",
      "Epoch 4\n",
      "TrainLoss:0.6614056825637817 TrainAccuracy:0.7394957983193278  TestLoss:0.674437940120697 TestAccuracy:0.6333333333333333\n",
      "Epoch 5\n",
      "TrainLoss:0.6578478813171387 TrainAccuracy:0.773109243697479  TestLoss:0.6718622446060181 TestAccuracy:0.6\n",
      "Epoch 6\n",
      "TrainLoss:0.6538050770759583 TrainAccuracy:0.7983193277310925  TestLoss:0.6690770983695984 TestAccuracy:0.5833333333333334\n",
      "Epoch 7\n",
      "TrainLoss:0.6494548320770264 TrainAccuracy:0.7941176470588235  TestLoss:0.66596919298172 TestAccuracy:0.65\n",
      "Epoch 8\n",
      "TrainLoss:0.645004391670227 TrainAccuracy:0.7983193277310925  TestLoss:0.6633468866348267 TestAccuracy:0.6666666666666666\n",
      "Epoch 9\n",
      "TrainLoss:0.6401904225349426 TrainAccuracy:0.8235294117647058  TestLoss:0.6612078547477722 TestAccuracy:0.6833333333333333\n",
      "Epoch 10\n",
      "TrainLoss:0.6352567076683044 TrainAccuracy:0.8235294117647058  TestLoss:0.6586353182792664 TestAccuracy:0.7166666666666667\n",
      "Epoch 11\n",
      "TrainLoss:0.6304663419723511 TrainAccuracy:0.8403361344537815  TestLoss:0.65594881772995 TestAccuracy:0.7333333333333333\n",
      "Epoch 12\n",
      "TrainLoss:0.6261899471282959 TrainAccuracy:0.8739495798319328  TestLoss:0.654192328453064 TestAccuracy:0.7166666666666667\n",
      "Epoch 13\n",
      "TrainLoss:0.6225771307945251 TrainAccuracy:0.9033613445378151  TestLoss:0.6529430150985718 TestAccuracy:0.6833333333333333\n",
      "Epoch 14\n",
      "TrainLoss:0.6208105087280273 TrainAccuracy:0.9117647058823529  TestLoss:0.6512759327888489 TestAccuracy:0.7333333333333333\n",
      "Epoch 15\n",
      "TrainLoss:0.6211037635803223 TrainAccuracy:0.9201680672268907  TestLoss:0.6510273814201355 TestAccuracy:0.7666666666666667\n",
      "Epoch 16\n",
      "TrainLoss:0.6227405071258545 TrainAccuracy:0.9117647058823529  TestLoss:0.6514971852302551 TestAccuracy:0.6666666666666666\n",
      "Epoch 17\n",
      "TrainLoss:0.6225453019142151 TrainAccuracy:0.8907563025210085  TestLoss:0.6506427526473999 TestAccuracy:0.75\n",
      "Epoch 18\n",
      "TrainLoss:0.6221844553947449 TrainAccuracy:0.9033613445378151  TestLoss:0.6516970992088318 TestAccuracy:0.7\n",
      "Epoch 19\n",
      "TrainLoss:0.620693564414978 TrainAccuracy:0.9117647058823529  TestLoss:0.6501932144165039 TestAccuracy:0.7166666666666667\n",
      "Epoch 20\n",
      "TrainLoss:0.6211357712745667 TrainAccuracy:0.9033613445378151  TestLoss:0.6489230394363403 TestAccuracy:0.75\n",
      "Epoch 21\n",
      "TrainLoss:0.620648205280304 TrainAccuracy:0.9159663865546218  TestLoss:0.6518388986587524 TestAccuracy:0.7166666666666667\n",
      "Epoch 22\n",
      "TrainLoss:0.6206142902374268 TrainAccuracy:0.9159663865546218  TestLoss:0.6516770720481873 TestAccuracy:0.7333333333333333\n",
      "Epoch 23\n",
      "TrainLoss:0.6212270259857178 TrainAccuracy:0.9243697478991597  TestLoss:0.6490563750267029 TestAccuracy:0.7666666666666667\n",
      "Epoch 24\n",
      "TrainLoss:0.6224185228347778 TrainAccuracy:0.9159663865546218  TestLoss:0.6533838510513306 TestAccuracy:0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(pars,lr=1e-3) # Optimizer\n",
    "# tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(25):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    X_batches, y_batches = shuffle_and_batch(X_train, y_train, 4, 67)\n",
    "    for i in range(len(X_batches)):\n",
    "        preds = feedForward(X_batches[i])\n",
    "#         loss = criterion(preds,labelToOneHot(y_batches[i])) \n",
    "        loss = criterion(preds,y_batches[i].long())+ 0.65*sum(p.pow(2.0).sum() for p in pars)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Checking model on training set\n",
    "    train_preds = feedForward(X_train)\n",
    "    train_loss = criterion(train_preds, y_train.long())\n",
    "#     train_loss = criterion(train_preds,labelToOneHot(y_train))\n",
    "    train_preds = labelize(train_preds)\n",
    "    train_prediction_comparisons = (y_train == train_preds)\n",
    "    train_accuracy = float(train_prediction_comparisons.sum())/float(y_train.shape[0])\n",
    "    print('TrainLoss:{} TrainAccuracy:{}'.format(train_loss.item(), train_accuracy), end='  ')\n",
    "    \n",
    "\n",
    "    # Checking model on testing set\n",
    "    test_preds = feedForward(X_test)\n",
    "    test_loss = criterion(test_preds, y_test.long())\n",
    "#     test_loss = criterion(test_preds,labelToOneHot(y_test))\n",
    "    test_preds = labelize(test_preds)\n",
    "    test_prediction_comparisons = (y_test == test_preds)\n",
    "    test_accuracy = float(test_prediction_comparisons.sum())/float(y_test.shape[0])\n",
    "    print('TestLoss:{} TestAccuracy:{}'.format(test_loss.item(), test_accuracy))\n",
    "    \n",
    "#     tb.add_scalar('TrainLoss',train_loss, epoch)\n",
    "#     tb.add_scalar('TestLoss',test_loss, epoch)\n",
    "#     tb.add_scalar('TrainAccuracy', train_accuracy, epoch)\n",
    "#     tb.add_scalar('TestAccuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcOnFXPuN8Oo"
   },
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmatrix(target,preds):\n",
    "\n",
    "    di = {}\n",
    "    \n",
    "    count00 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==0.0 and j==0.0:\n",
    "            count00+=1\n",
    "    di['count00'] = count00\n",
    "        \n",
    "    \n",
    "    count11 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==1. and j==1.:\n",
    "            count11+=1\n",
    "    di['count11'] = count11\n",
    "\n",
    "    \n",
    "    count01 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==0. and j==1.:\n",
    "            count01+=1\n",
    "    di['count01'] = count01\n",
    "    \n",
    "    count10 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==1. and j==0.:\n",
    "            count10+=1\n",
    "    di['count10'] = count10\n",
    "        \n",
    "    print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,   1],\n",
       "       [ 19, 100]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training Set Confusion matrix')\n",
    "confusion_matrix(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  6],\n",
       "       [11, 19]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing Set Confusion matrix')\n",
    "confusion_matrix(y_test, test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = pickle.load(open(f'X5040_32_raw.pkl', 'rb'))\n",
    "yraw = pickle.load(open(f'y5040_32_raw.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawAccuracy:0.6358186586736605  "
     ]
    }
   ],
   "source": [
    "raw_preds = feedForward(Xraw)\n",
    "# raw_loss = criterion(raw_preds, labelToOneHot(yraw))\n",
    "raw_preds = labelize(raw_preds)\n",
    "raw_prediction_comparisons = (yraw == raw_preds)\n",
    "raw_accuracy = float(raw_prediction_comparisons.sum())/float(yraw.shape[0])\n",
    "print('Raw Dataset Accuracy:{}'.format(raw_accuracy), end='  ')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 147,    2],\n",
       "       [ 970, 1550]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Raw Dataset Confusion Matrix')\n",
    "confusion_matrix(yraw, raw_preds) #target on the vertical axis and preds on the horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317607640433309"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Raw Dataset F1-Score')\n",
    "f1_score(yraw, raw_preds, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 misclassification: 1.342281879194631 %\n"
     ]
    }
   ],
   "source": [
    "print('0 misclassification: '+str(confusion_matrix(yraw, raw_preds)[0][1]/confusion_matrix(yraw, raw_preds)[0].sum()*100)+' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 misclassification: 38.492063492063494 %\n"
     ]
    }
   ],
   "source": [
    "print('1 misclassification: '+str(confusion_matrix(yraw, raw_preds)[1][0]/confusion_matrix(yraw, raw_preds)[1].sum()*100)+' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.Tensor([[1,2,3]])\n",
    "# b = nn.Linear(3,2)\n",
    "# c = nn.Dropout(p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([298, 3, 300, 300]), torch.Size([298]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pickle.load(open(f'X298.pkl', 'rb'))\n",
    "b = pickle.load(open(f'y298.pkl', 'rb'))\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "onezeroes = []\n",
    "for i in range(Xraw.shape[0]):\n",
    "    if yraw[i] == 1. and raw_preds[i] == 0.:\n",
    "        onezeroes.append(i)\n",
    "\n",
    "onezeroes = torch.Tensor(onezeroes).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "onezeroimages = Xraw[onezeroes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2669, 3, 32, 32])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xraw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0298eb1630>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(onezeroimages[5].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# tb = SummaryWriter()\n",
    "# grid = torchvision.utils.make_grid(onezeroimages[:10])\n",
    "# tb.add_image('ims',grid)\n",
    "# tb.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LeNet5.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
