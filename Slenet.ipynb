{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pickle.load(open(f'X_train298.pkl', 'rb'))\n",
    "# y_train = pickle.load(open(f'y_train298.pkl', 'rb'))\n",
    "# X_test = pickle.load(open(f'X_test298.pkl', 'rb'))\n",
    "# y_test = pickle.load(open(f'y_test298.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(f'X298.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'y298.pkl', 'rb'))\n",
    "# X_train = pickle.load(open(f'X5040.pkl', 'rb'))\n",
    "# y_train = pickle.load(open(f'y5040.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalized(X,s):\n",
    "    flattened_channels = X.reshape(3,-1)\n",
    "    channel_mean = flattened_channels.mean(dim = 1)\n",
    "    channel_stddev = flattened_channels.std(dim = 1)\n",
    "    preprocess2 = transforms.Compose([\n",
    "                      transforms.Normalize(channel_mean, channel_stddev)\n",
    "    ])\n",
    "\n",
    "\n",
    "    temptwo = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess2(X[i])\n",
    "        temptwo = torch.cat([temptwo, a.reshape(1,3,s,s)])\n",
    "  \n",
    "    return temptwo\n",
    "\n",
    "\n",
    "def imageSetResize(newSize,X):\n",
    "    preprocess1 = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize(newSize),\n",
    "                        transforms.ToTensor()])\n",
    "  \n",
    "    temp = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess1(X[i])\n",
    "        temp = torch.cat([temp, a.reshape(1,3,newSize,newSize)])\n",
    "\n",
    "    return temp \n",
    "\n",
    "\n",
    "def splitTrainTest(X,y):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    ul = math.floor(0.8*X.shape[0])\n",
    "    train_indices = shuffled_indices[:ul]\n",
    "    test_indices = shuffled_indices[ul:]\n",
    "    # train_indices.shape[0] + test_indices.shape[0]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]  \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "    print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def labelize(p):\n",
    "    labelized_preds = []\n",
    "    for i in p:\n",
    "        l = 0. if i[0]>i[1] else 1.\n",
    "        labelized_preds.append(l)\n",
    "\n",
    "    return torch.tensor(labelized_preds)\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_and_batch(X,y,num,bs):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    newX = X[shuffled_indices]\n",
    "    newY = y[shuffled_indices]\n",
    "\n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    for i in range(num):\n",
    "        X_batches.append(X[i*bs:(i+1)*bs])\n",
    "        y_batches.append(y_train[i*bs:(i+1)*bs])\n",
    "\n",
    "    return X_batches, y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = cCrop(X_train.float(),150)\n",
    "imsize = 32\n",
    "X_train = imageSetResize(imsize, X_train.float())\n",
    "X_train = getNormalized(X_train.float(),imsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lenetModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(lenetModel, self).__init__()\n",
    "        self.c1 = nn.Conv2d(3,6, kernel_size = 5)\n",
    "#         self.dropout1 = nn.Dropout(p=0.6)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "     \n",
    "        self.first_cons6_filterlist = nn.ModuleList([])\n",
    "        self.second_cons6_filterlist = nn.ModuleList([])\n",
    "        self.third_cons3_filterlist = nn.ModuleList([])\n",
    "        self.fourth_last1_filterlist = nn.ModuleList([])\n",
    "        \n",
    "        for i in range(6):\n",
    "            self.first_cons6_filterlist.append(nn.Conv2d(3,1,kernel_size = 5))\n",
    "        for i in range(6):\n",
    "            self.second_cons6_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "        for i in range(3):\n",
    "            self.third_cons3_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "        self.fourth_last1_filterlist.append(nn.Conv2d(6,1,kernel_size = 5))\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "       \n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size = 5)\n",
    "        self.bn3= nn.BatchNorm2d(120)\n",
    "        \n",
    "        self.ll1 = nn.Linear(120, 84)\n",
    "        self.ll2 = nn.Linear(84,2)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        nos = x.shape[0]\n",
    "        ef = lambda x,y: torch.index_select(y,1,torch.tensor(x))\n",
    "        c1_out = self.c1(x)\n",
    "        out = F.relu(self.bn1(self.pool1(c1_out))) #put bn1\n",
    "        lione = [ef([0,1,2],out),ef([1,2,3],out), ef([2,3,4],out), ef([3,4,5],out), ef([0,4,5],out),ef([0,1,5],out)]\n",
    "        litwo = [ef([0,1,2,3],out),ef([1,2,3,4],out), ef([2,3,4,5],out), ef([0,3,4,5],out), ef([0,1,4,5],out),ef([0,1,2,5],out)]\n",
    "        lithree = [ef([0,1,3,4],out),ef([1,2,4,5],out), ef([0,2,3,5],out)]\n",
    "        lifour = [ef([0,1,2,3,4,5],out)]\n",
    "        feature_maps1 = []\n",
    "        feature_maps2 = []\n",
    "        feature_maps3 = []\n",
    "        feature_maps4 = []\n",
    "        for i in range(6):\n",
    "            feature_maps1.append(self.first_cons6_filterlist[i](lione[i]))\n",
    "        for i in range(6):\n",
    "            feature_maps2.append(self.second_cons6_filterlist[i](litwo[i]))\n",
    "        for i in range(3):\n",
    "            feature_maps3.append(self.third_cons3_filterlist[i](lithree[i]))\n",
    "        for i in range(1):\n",
    "            feature_maps4.append(self.fourth_last1_filterlist[i](lifour[i]))\n",
    "        fms = []\n",
    "        fms.extend(feature_maps1)\n",
    "        fms.extend(feature_maps2)\n",
    "        fms.extend(feature_maps3)\n",
    "        fms.extend(feature_maps4)\n",
    "        tfms = torch.Tensor([])\n",
    "        for i in fms:\n",
    "            tfms = torch.cat([tfms, i], dim=1)\n",
    "        c2_out = F.relu(self.bn2(self.pool2(tfms))) # put bn2\n",
    "        c3_out = self.bn3(self.conv3(c2_out)) #put bn3\n",
    "        c3_out = c3_out.reshape(nos,120)\n",
    "        ll1_out = F.relu(self.ll1(c3_out))\n",
    "        ll2_out = self.ll2(ll1_out)\n",
    "        preds = nn.Softmax(dim=1)(ll2_out)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = lenetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = './1.pth'\n",
    "# print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "# print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelToOneHot(x):\n",
    "    \n",
    "    onehot = []\n",
    "    for i in x:\n",
    "        if i == 1.0:\n",
    "            onehot.append([0.,1.])\n",
    "        else:\n",
    "            onehot.append([1.,0.])\n",
    "            \n",
    "    return torch.Tensor(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params = m1.parameters(),lr=1e-3) # Optimizer\n",
    "# tb = SummaryWriter()\n",
    "prev_testacc = -float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    m1.train()\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    X_batches, y_batches = shuffle_and_batch(X_train, y_train, 76, 67)\n",
    "   \n",
    "    for i in range(len(X_batches)):\n",
    "        preds = m1(X_batches[i])\n",
    "#         loss = criterion(preds,labelToOneHot(y_batches[i])) \n",
    "        loss = criterion(preds,y_batches[i].long())#+ 0.12*sum(p.pow(2.0).sum() for p in m1.parameters())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    m1.eval()\n",
    "    # Checking model on training set\n",
    "    train_preds = m1(X_train)\n",
    "    train_loss = criterion(train_preds, y_train.long())\n",
    "#     train_loss = criterion(train_preds,labelToOneHot(y_train))\n",
    "    train_preds = labelize(train_preds)\n",
    "    train_prediction_comparisons = (y_train == train_preds)\n",
    "    train_accuracy = float(train_prediction_comparisons.sum())/float(y_train.shape[0])\n",
    "    print('TrainLoss:{} TrainAccuracy:{}'.format(train_loss.item(), train_accuracy), end='  ')\n",
    "    \n",
    "\n",
    "    # Checking model on testing set\n",
    "#     test_preds = m1(X_test)\n",
    "#     test_loss = criterion(test_preds, y_test.long())\n",
    "# #     test_loss = criterion(test_preds,labelToOneHot(y_test))\n",
    "#     test_preds = labelize(test_preds)\n",
    "#     test_prediction_comparisons = (y_test == test_preds)\n",
    "#     test_accuracy = float(test_prediction_comparisons.sum())/float(y_test.shape[0])\n",
    "#     print('TestLoss:{} TestAccuracy:{}'.format(test_loss.item(), test_accuracy))\n",
    "#     if test_accuracy < prev_testacc and prev_testacc>0.7:\n",
    "#         break\n",
    "# #     state_dict = m1.state_dict()\n",
    "# #     torch.save(state_dict, model_path)\n",
    "#     prev_testacc = test_accuracy\n",
    "    \n",
    "    \n",
    "    m1.eval()\n",
    "    Xraw = pickle.load(open(f'X5040_32_raw.pkl', 'rb'))\n",
    "    yraw = pickle.load(open(f'y5040_32_raw.pkl', 'rb'))\n",
    "\n",
    "    raw_preds = m1(Xraw)\n",
    "#     train_loss = criterion(raw_preds, yraw.long())\n",
    "#     raw_loss = criterion(raw_preds, labelToOneHot(yraw)) #KLDivergence\n",
    "    raw_preds = labelize(raw_preds)\n",
    "    raw_prediction_comparisons = (yraw == raw_preds)\n",
    "    raw_accuracy = float(raw_prediction_comparisons.sum())/float(yraw.shape[0])\n",
    "#     print('RawAccuracy:{}'.format(raw_accuracy), end='\\n') \n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(yraw, raw_preds)\n",
    "    acc0 = cm[0][0]/cm[0].sum()\n",
    "    acc1 = cm[1][1]/cm[1].sum()\n",
    "    print('[0]{}% [1]{}%'.format(acc0*100.0, acc1*100.0))\n",
    "    \n",
    "    \n",
    "#     tb.add_scalar('Accuracy',raw_accuracy, epoch)\n",
    "#     tb.add_scalar('0 Accuracy',acc0, epoch)\n",
    "#     tb.add_scalar('1 Accuracy', acc1, epoch)\n",
    "#     tb.add_scalar('TestAccuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.eval()\n",
    "# model_path = './10.pth'hghgjg\n",
    "# state_dict = m1.state_dict()\n",
    "# torch.save(state_dict, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.eval()\n",
    "acc0ss = []\n",
    "acc1ss = []\n",
    "for i in range(10):\n",
    "    raw_preds = m1(Xraw)\n",
    "    raw_preds = labelize(raw_preds)\n",
    "    raw_prediction_comparisons = (yraw == raw_preds)\n",
    "    raw_accuracy = float(raw_prediction_comparisons.sum())/float(yraw.shape[0])\n",
    "#     print('RawAccuracy:{}'.format(raw_accuracy), end='\\n')  \n",
    "    cm = confusion_matrix(yraw, raw_preds)\n",
    "\n",
    "    acc0ss.append((cm[0][0]/cm[0].sum())/10.0)\n",
    "    acc1ss.append((cm[1][1]/cm[1].sum())/10.0)\n",
    "    \n",
    "print('0 Accuracy: {}'.format(sum(acc0ss)))\n",
    "print('1 Accuracy: {}'.format(sum(acc1ss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
