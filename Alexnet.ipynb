{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(f'X_train298.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'y_train298.pkl', 'rb'))\n",
    "X_test = pickle.load(open(f'X_test298.pkl', 'rb'))\n",
    "y_test = pickle.load(open(f'y_test298.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(f'X2669.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'y2669.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalized(X,s):\n",
    "    flattened_channels = X.reshape(3,-1)\n",
    "    channel_mean = flattened_channels.mean(dim = 1)\n",
    "    channel_stddev = flattened_channels.std(dim = 1)\n",
    "    preprocess2 = transforms.Compose([\n",
    "                      transforms.Normalize(channel_mean, channel_stddev)\n",
    "    ])\n",
    "\n",
    "\n",
    "    temptwo = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess2(X[i])\n",
    "        temptwo = torch.cat([temptwo, a.reshape(1,3,s,s)])\n",
    "  \n",
    "    return temptwo\n",
    "\n",
    "\n",
    "def imageSetResize(newSize,X):\n",
    "    preprocess1 = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize(newSize),\n",
    "                        transforms.ToTensor()])\n",
    "  \n",
    "    temp = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess1(X[i])\n",
    "        temp = torch.cat([temp, a.reshape(1,3,newSize,newSize)])\n",
    "\n",
    "    return temp \n",
    "\n",
    "\n",
    "def splitTrainTest(X,y):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    ul = math.floor(0.8*X.shape[0])\n",
    "    train_indices = shuffled_indices[:ul]\n",
    "    test_indices = shuffled_indices[ul:]\n",
    "    # train_indices.shape[0] + test_indices.shape[0]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]  \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "    print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def labelize(p):\n",
    "    labelized_preds = []\n",
    "    for i in p:\n",
    "        l = 0. if i[0]>i[1] else 1.\n",
    "        labelized_preds.append(l)\n",
    "\n",
    "    return torch.tensor(labelized_preds)\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_and_batch(X,y,num,bs):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    newX = X[shuffled_indices]\n",
    "    newY = y[shuffled_indices]\n",
    "\n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    for i in range(num):\n",
    "        X_batches.append(X[i*bs:(i+1)*bs])\n",
    "        y_batches.append(y_train[i*bs:(i+1)*bs])\n",
    "\n",
    "    return X_batches, y_batches\n",
    "\n",
    "\n",
    "def cCrop(X, dim):\n",
    "    p = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.CenterCrop(dim),\n",
    "                        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    temp = torch.Tensor([])\n",
    "    for i in X:\n",
    "        a = p(i)\n",
    "        temp = torch.cat([temp,a.unsqueeze(0)])\n",
    "  \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2669, 3, 227, 227])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = cCrop(X_train,227)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 227\n",
    "# X_train = imageSetResize(imsize, X_train.float())\n",
    "X_train = getNormalized(X_train.float(),imsize)\n",
    "# X_test = imageSetResize(imsize, X_test.float())\n",
    "# X_test = getNormalized(X_test.float(),imsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,96,kernel_size=11,stride = 4)\n",
    "        self.pool1 = nn.MaxPool2d(3, stride = 2)\n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.conv2 = nn.Conv2d(96,256,kernel_size=1,stride = 1)\n",
    "        self.pool2 = nn.MaxPool2d(3, stride = 2)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.conv3 = nn.Conv2d(256,384,kernel_size=1,stride = 1)\n",
    "        self.conv4 = nn.Conv2d(384,384,kernel_size=1,stride = 1)\n",
    "        self.conv5 = nn.Conv2d(384,256,kernel_size=1,stride = 1)\n",
    "        self.pool3 = nn.MaxPool2d(3, stride = 2)\n",
    "        self.ll1 = nn.Linear(9216,4096)\n",
    "        self.ll2 = nn.Linear(4096,4096)\n",
    "        self.ll3 = nn.Linear(4096,2)\n",
    "        \n",
    "        \n",
    "            \n",
    "    def forward(self,X):\n",
    "        print('Image: {}'.format(X.shape))\n",
    "        out = F.relu(self.conv1(X))\n",
    "        print('conv1 + relu: {}'.format(out.shape))\n",
    "        out = self.pool1(out)\n",
    "        print('Pool1: {}'.format(out.shape))\n",
    "        out = self.bn1(out)\n",
    "        print('Batch Norm: {}'.format(out.shape))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        print('conv2 + relu: {}'.format(out.shape))\n",
    "        out = self.pool2(out)\n",
    "        print('Pool2: {}'.format(out.shape))\n",
    "        out = self.bn2(out)\n",
    "        print('Batch Norm: {}'.format(out.shape))\n",
    "        out = F.relu(self.conv3(out))\n",
    "        print('conv3 + relu: {}'.format(out.shape))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        print('conv4 + relu: {}'.format(out.shape))\n",
    "        out = F.relu(self.conv5(out))\n",
    "        print('conv5 + relu: {}'.format(out.shape))\n",
    "        out = self.pool3(out)\n",
    "        print('Pool3: {}'.format(out.shape))\n",
    "        out = nn.Dropout(p=0.5)(out)\n",
    "        print('Dropout: {}'.format(out.shape))\n",
    "        out = F.relu(out.reshape(X.shape[0],-1))\n",
    "        print('Flatten + relu: {}'.format(out.shape))\n",
    "        out = F.relu(self.ll1(out))\n",
    "        print('linear + relu: {}'.format(out.shape))\n",
    "        out = F.relu(self.ll2(out))\n",
    "        print('linear + relu: {}'.format(out.shape))\n",
    "        out = F.relu(self.ll3(out))\n",
    "        print('linear + relu: {}'.format(out.shape))\n",
    "        sm = torch.softmax(out, dim=0)\n",
    "        return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params = m1.parameters(),lr=1e-3) # Optimizer\n",
    "# tb = SummaryWriter()\n",
    "prev_testacc = -float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "#     m1.train()\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    X_batches, y_batches = shuffle_and_batch(X_train, y_train, 4, 67)\n",
    "    for i in range(len(X_batches)):\n",
    "        preds = m1(X_batches[i])\n",
    "#         loss = criterion(preds,labelToOneHot(y_batches[i])) \n",
    "        loss = criterion(preds,y_batches[i].long())+ 0.65*sum(p.pow(2.0).sum() for p in m1.parameters())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "#     m1.eval()\n",
    "    # Checking model on training set\n",
    "    train_preds = m1(X_train)\n",
    "    train_loss = criterion(train_preds, y_train.long())\n",
    "#     train_loss = criterion(train_preds,labelToOneHot(y_train))\n",
    "    train_preds = labelize(train_preds)\n",
    "    train_prediction_comparisons = (y_train == train_preds)\n",
    "    train_accuracy = float(train_prediction_comparisons.sum())/float(y_train.shape[0])\n",
    "    print('TrainLoss:{} TrainAccuracy:{}'.format(train_loss.item(), train_accuracy), end='  ')\n",
    "    \n",
    "\n",
    "    # Checking model on testing set\n",
    "#     test_preds = m1(X_test)\n",
    "#     test_loss = criterion(test_preds, y_test.long())\n",
    "# #     test_loss = criterion(test_preds,labelToOneHot(y_test))\n",
    "#     test_preds = labelize(test_preds)\n",
    "#     test_prediction_comparisons = (y_test == test_preds)\n",
    "#     test_accuracy = float(test_prediction_comparisons.sum())/float(y_test.shape[0])\n",
    "#     print('TestLoss:{} TestAccuracy:{}'.format(test_loss.item(), test_accuracy))\n",
    "#     if test_accuracy < prev_testacc and prev_testacc>0.7:\n",
    "#         break\n",
    "# #     state_dict = m1.state_dict()\n",
    "# #     torch.save(state_dict, model_path)\n",
    "#     prev_testacc = test_accuracy\n",
    "\n",
    "    m1.eval()\n",
    "    Xraw = pickle.load(open(f'X2669.pkl', 'rb'))\n",
    "    yraw = pickle.load(open(f'y2669.pkl', 'rb'))\n",
    "\n",
    "    raw_preds = m1(Xraw)\n",
    "#     train_loss = criterion(raw_preds, yraw.long())\n",
    "#     raw_loss = criterion(raw_preds, labelToOneHot(yraw)) #KLDivergence\n",
    "    raw_preds = labelize(raw_preds)\n",
    "    raw_prediction_comparisons = (yraw == raw_preds)\n",
    "    raw_accuracy = float(raw_prediction_comparisons.sum())/float(yraw.shape[0])\n",
    "#     print('RawAccuracy:{}'.format(raw_accuracy), end='\\n') \n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(yraw, raw_preds)\n",
    "    acc0 = cm[0][0]/cm[0].sum()\n",
    "    acc1 = cm[1][1]/cm[1].sum()\n",
    "    print('[0]{}% [1]{}%'.format(acc0*100.0, acc1*100.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa = y_train == 0.\n",
    "# aa[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = X_train[10]\n",
    "# b = cCrop(a.unsqueeze(0),227)\n",
    "\n",
    "# plt.imshow(b[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(X_train[10].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
