{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shouvikcirca/PCB_Defect_Detection/blob/master/LeNet5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXw93V3KBuGL"
   },
   "source": [
    "# LeNet5.3_BatchNorm_ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x42ZnnA0BuGM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shouvik/Desktop/DeepLearning/dl/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "JC2jsHuXB2q6",
    "outputId": "dfcfaef2-d198-4066-ba13-15707c384c17"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoSCktJAB60c"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# X = np.load('drive/My Drive/Copy of xtrain.npy')\n",
    "# y = np.load('drive/My Drive/Copy of ytrain.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local machine\n",
    "X_train = pickle.load(open(f'X_train298.pkl', 'rb'))\n",
    "y_train = pickle.load(open(f'y_train298.pkl', 'rb'))\n",
    "X_test = pickle.load(open(f'X_test298.pkl', 'rb'))\n",
    "y_test = pickle.load(open(f'y_test298.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 3, 300, 300])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q1zTL2ONB9Lw",
    "outputId": "37bc1812-d9fe-4334-9998-d17f11e3564c"
   },
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# X = torch.from_numpy(X)\n",
    "# X = X.permute(0,3,1,2)\n",
    "# y = torch.from_numpy(y)\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLB5FrOMBuGR"
   },
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUC_1EbfBuGS"
   },
   "outputs": [],
   "source": [
    "def getNormalized(X,s):\n",
    "    flattened_channels = X.reshape(3,-1)\n",
    "    channel_mean = flattened_channels.mean(dim = 1)\n",
    "    channel_stddev = flattened_channels.std(dim = 1)\n",
    "    preprocess2 = transforms.Compose([\n",
    "                      transforms.Normalize(channel_mean, channel_stddev)\n",
    "    ])\n",
    "\n",
    "\n",
    "    temptwo = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess2(X[i])\n",
    "        temptwo = torch.cat([temptwo, a.reshape(1,3,s,s)])\n",
    "  \n",
    "    return temptwo\n",
    "\n",
    "\n",
    "def imageSetResize(newSize,X):\n",
    "    preprocess1 = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize(newSize),\n",
    "                        transforms.ToTensor()])\n",
    "  \n",
    "    temp = torch.tensor([])\n",
    "    for i in range(X.shape[0]):\n",
    "        a = preprocess1(X[i])\n",
    "        temp = torch.cat([temp, a.reshape(1,3,newSize,newSize)])\n",
    "\n",
    "    return temp \n",
    "\n",
    "\n",
    "def splitTrainTest(X,y):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    ul = math.floor(0.8*X.shape[0])\n",
    "    train_indices = shuffled_indices[:ul]\n",
    "    test_indices = shuffled_indices[ul:]\n",
    "    # train_indices.shape[0] + test_indices.shape[0]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]  \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "    print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def labelize(p):\n",
    "    labelized_preds = []\n",
    "    for i in p:\n",
    "        l = 0. if i[0]>i[1] else 1.\n",
    "        labelized_preds.append(l)\n",
    "\n",
    "    return torch.tensor(labelized_preds)\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_and_batch(X,y,num,bs):\n",
    "    shuffled_indices = torch.randperm(X.shape[0])\n",
    "    newX = X[shuffled_indices]\n",
    "    newY = y[shuffled_indices]\n",
    "\n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    for i in range(num):\n",
    "        X_batches.append(X[i*bs:(i+1)*bs])\n",
    "        y_batches.append(y_train[i*bs:(i+1)*bs])\n",
    "\n",
    "    return X_batches, y_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 32\n",
    "X_train = imageSetResize(imsize, X_train.float())\n",
    "X_train = getNormalized(X_train.float(),imsize)\n",
    "X_test = imageSetResize(imsize, X_test.float())\n",
    "X_test = getNormalized(X_test.float(),imsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qj6jcCXLBuGW"
   },
   "source": [
    "Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQy8vua7BuGX"
   },
   "outputs": [],
   "source": [
    "pars = []\n",
    "\n",
    "\n",
    "#C1\n",
    "c1 = nn.Conv2d(3,6, kernel_size = 5)\n",
    "pars = pars + list(c1.parameters())\n",
    "\n",
    "#S2\n",
    "pool1 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "# BN1\n",
    "bn1 = nn.BatchNorm2d(6)\n",
    "pars = pars + list(bn1.parameters())\n",
    "\n",
    "#C3\n",
    "first_cons6_filterlist = []\n",
    "second_cons6_filterlist = []\n",
    "third_cons3_filterlist = []\n",
    "fourth_last1_filterlist = []\n",
    "for i in range(6):\n",
    "    first_cons6_filterlist.append(nn.Conv2d(3,1,kernel_size = 5))\n",
    "    pars = pars + list(first_cons6_filterlist[-1].parameters())\n",
    "    \n",
    "for i in range(6):\n",
    "    second_cons6_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "    pars = pars + list(second_cons6_filterlist[-1].parameters())\n",
    "    \n",
    "for i in range(3):\n",
    "    third_cons3_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
    "    pars = pars + list(third_cons3_filterlist[-1].parameters())\n",
    "\n",
    "fourth_last1_filterlist = [nn.Conv2d(6,1,kernel_size = 5)]\n",
    "pars = pars + list(fourth_last1_filterlist[-1].parameters())\n",
    "\n",
    "#S4\n",
    "pool2 = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "\n",
    "#BN2\n",
    "bn2 = nn.BatchNorm2d(16)\n",
    "pars = pars + list(bn2.parameters())\n",
    "\n",
    "\n",
    "#C5\n",
    "conv3 = nn.Conv2d(16, 120, kernel_size = 5)\n",
    "pars = pars + list(conv3.parameters())\n",
    "\n",
    "\n",
    "#BN3\n",
    "bn3= nn.BatchNorm2d(120)\n",
    "pars = pars + list(bn3.parameters())\n",
    "\n",
    "\n",
    "#F6\n",
    "ll1 = nn.Linear(120, 84)\n",
    "\n",
    "\n",
    "#F7\n",
    "ll2 = nn.Linear(84,2)\n",
    "pars = pars + list(ll1.parameters()) + list(ll2.parameters())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmnhG202loT5"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# criterion = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5QbXFhbBuGa"
   },
   "outputs": [],
   "source": [
    "# def displayDetails(lone = None, ltwo=None):\n",
    "#     if lone is not None:\n",
    "#         a = lone\n",
    "#         print('--------')\n",
    "#         for i in a[0]:\n",
    "#             print(i)\n",
    "#         print('--------')\n",
    "#         for i in a[1]:\n",
    "#             print(i)\n",
    "#         print('-------')\n",
    "#         for i in a[2]:\n",
    "#             print(i)\n",
    "#         print('-------')\n",
    "#         for i in a[3]:\n",
    "#             print(i)\n",
    "#     if ltwo is not None:\n",
    "#         a = ltwo\n",
    "#         for i in a:\n",
    "#             print('-----')\n",
    "#             for j in i:\n",
    "#                 print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2xDzuPRBuGe"
   },
   "outputs": [],
   "source": [
    "# displayDetails(lone = [first_cons6_filterlist,second_cons6_filterlist,third_cons3_filterlist,fourth_last1_filterlist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-jMzvZ1BuGh"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DC6H9PuXBuGi"
   },
   "outputs": [],
   "source": [
    "# resized_imageset = imageSetResize(32, X.float())\n",
    "# normalized_imageset = getNormalized(resized_imageset.float(),32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "U5d3IZAnDsfO",
    "outputId": "6f4c9667-7c45-4e9f-dd43-fe5e1a7bdf3c"
   },
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = splitTrainTest(resized_imageset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(X_train, open(\"xtrain298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(X_test, open(\"xtest298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(y_train, open(\"ytrain298.pkl\", 'wb'), protocol=4)\n",
    "# pickle.dump(y_test, open(\"ytest298.pkl\", 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpmIw5uaBuGl"
   },
   "outputs": [],
   "source": [
    "def ef(li, c1_out):\n",
    "    return torch.index_select(c1_out, 1, torch.tensor(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train -> [0]:119 [1]:119\n",
      "y_test -> [0]:30 [1]:30\n"
     ]
    }
   ],
   "source": [
    "print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
    "print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdR1kcwSBuGp"
   },
   "outputs": [],
   "source": [
    "def feedForward(X):\n",
    "    \n",
    "    global c1\n",
    "    global first_cons6_filterlist\n",
    "    global second_cons6_filterlist\n",
    "    global third_cons3_filterlist\n",
    "    global fourth_last1_filterlist\n",
    "    nos = X.shape[0]\n",
    "    c1_out = c1(X)\n",
    "    out = F.relu(bn1(pool1(c1_out)))\n",
    "    lione = [ef([0,1,2],out),ef([1,2,3],out), ef([2,3,4],out), ef([3,4,5],out), ef([0,4,5],out),ef([0,1,5],out)]\n",
    "    litwo = [ef([0,1,2,3],out),ef([1,2,3,4],out), ef([2,3,4,5],out), ef([0,3,4,5],out), ef([0,1,4,5],out),ef([0,1,2,5],out)]\n",
    "    lithree = [ef([0,1,3,4],out),ef([1,2,4,5],out), ef([0,2,3,5],out)]\n",
    "    lifour = [ef([0,1,2,3,4,5],out)]\n",
    "    feature_maps1 = []\n",
    "    feature_maps2 = []\n",
    "    feature_maps3 = []\n",
    "    feature_maps4 = []\n",
    "    for i in range(6):\n",
    "        feature_maps1.append(first_cons6_filterlist[i](lione[i]))\n",
    "    for i in range(6):\n",
    "        feature_maps2.append(second_cons6_filterlist[i](litwo[i]))\n",
    "    for i in range(3):\n",
    "        feature_maps3.append(third_cons3_filterlist[i](lithree[i]))\n",
    "    for i in range(1):\n",
    "        feature_maps4.append(fourth_last1_filterlist[i](lifour[i]))\n",
    "    fms = []\n",
    "    fms.extend(feature_maps1)\n",
    "    fms.extend(feature_maps2)\n",
    "    fms.extend(feature_maps3)\n",
    "    fms.extend(feature_maps4)\n",
    "    tfms = torch.Tensor([])\n",
    "    for i in fms:\n",
    "        tfms = torch.cat([tfms, i], dim=1)\n",
    "    c2_out = F.relu(bn2(pool2(tfms)))\n",
    "    c3_out = bn3(conv3(c2_out))\n",
    "    c3_out = c3_out.reshape(nos,120)\n",
    "    ll1_out = F.relu(ll1(c3_out))\n",
    "    ll2_out = ll2(ll1_out)\n",
    "#     preds = nn.Softmax(dim=1)(ll2_out)\n",
    "    preds = F.log_softmax(ll2_out, dim=1)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelToOneHot(x):\n",
    "    t = torch.zeros(x.shape[0],2).float()\n",
    "    for i in range(x.shape[0]):\n",
    "        if x[i] == 0.:\n",
    "            t[i][0] = 1\n",
    "        else:\n",
    "            t[i][1] = 1\n",
    "            \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tDMvGyz7BuGs",
    "outputId": "d986b8d5-fe35-49c7-ef87-6bfe2d4de5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "TrainLoss:0.6626825332641602 TrainAccuracy:0.6512605042016807  TestLoss:0.6604188680648804 TestAccuracy:0.6666666666666666\n",
      "Epoch 1\n",
      "TrainLoss:0.6277774572372437 TrainAccuracy:0.726890756302521  TestLoss:0.6447160840034485 TestAccuracy:0.6666666666666666\n",
      "Epoch 2\n",
      "TrainLoss:0.6078929305076599 TrainAccuracy:0.7941176470588235  TestLoss:0.6386173367500305 TestAccuracy:0.65\n",
      "Epoch 3\n",
      "TrainLoss:0.590805172920227 TrainAccuracy:0.8319327731092437  TestLoss:0.6318234205245972 TestAccuracy:0.6666666666666666\n",
      "Epoch 4\n",
      "TrainLoss:0.5726038217544556 TrainAccuracy:0.8487394957983193  TestLoss:0.6227000951766968 TestAccuracy:0.6666666666666666\n",
      "Epoch 5\n",
      "TrainLoss:0.5555788278579712 TrainAccuracy:0.8529411764705882  TestLoss:0.6150354146957397 TestAccuracy:0.7\n",
      "Epoch 6\n",
      "TrainLoss:0.5392376184463501 TrainAccuracy:0.8739495798319328  TestLoss:0.6081900000572205 TestAccuracy:0.7333333333333333\n",
      "Epoch 7\n",
      "TrainLoss:0.523076593875885 TrainAccuracy:0.8991596638655462  TestLoss:0.6020727753639221 TestAccuracy:0.7\n",
      "Epoch 8\n",
      "TrainLoss:0.5055418610572815 TrainAccuracy:0.9033613445378151  TestLoss:0.5933114886283875 TestAccuracy:0.7166666666666667\n",
      "Epoch 9\n",
      "TrainLoss:0.48954641819000244 TrainAccuracy:0.907563025210084  TestLoss:0.5873028635978699 TestAccuracy:0.7166666666666667\n",
      "Epoch 10\n",
      "TrainLoss:0.4745200574398041 TrainAccuracy:0.9033613445378151  TestLoss:0.5859376192092896 TestAccuracy:0.7333333333333333\n",
      "Epoch 11\n",
      "TrainLoss:0.458680659532547 TrainAccuracy:0.9117647058823529  TestLoss:0.5812652111053467 TestAccuracy:0.7333333333333333\n",
      "Epoch 12\n",
      "TrainLoss:0.4416687786579132 TrainAccuracy:0.9243697478991597  TestLoss:0.5790750980377197 TestAccuracy:0.7666666666666667\n",
      "Epoch 13\n",
      "TrainLoss:0.42704281210899353 TrainAccuracy:0.9327731092436975  TestLoss:0.5667926669120789 TestAccuracy:0.7833333333333333\n",
      "Epoch 14\n",
      "TrainLoss:0.4094806909561157 TrainAccuracy:0.9411764705882353  TestLoss:0.5660478472709656 TestAccuracy:0.7666666666666667\n",
      "Epoch 15\n",
      "TrainLoss:0.3940730094909668 TrainAccuracy:0.9411764705882353  TestLoss:0.5649974346160889 TestAccuracy:0.75\n",
      "Epoch 16\n",
      "TrainLoss:0.3972005248069763 TrainAccuracy:0.9411764705882353  TestLoss:0.5897956490516663 TestAccuracy:0.7166666666666667\n",
      "Epoch 17\n",
      "TrainLoss:0.3934386074542999 TrainAccuracy:0.9033613445378151  TestLoss:0.5212429761886597 TestAccuracy:0.7833333333333333\n",
      "Epoch 18\n",
      "TrainLoss:0.36569511890411377 TrainAccuracy:0.9327731092436975  TestLoss:0.5389031171798706 TestAccuracy:0.75\n",
      "Epoch 19\n",
      "TrainLoss:0.3542573153972626 TrainAccuracy:0.9411764705882353  TestLoss:0.49969106912612915 TestAccuracy:0.8166666666666667\n",
      "Epoch 20\n",
      "TrainLoss:0.3442590534687042 TrainAccuracy:0.9411764705882353  TestLoss:0.4906778931617737 TestAccuracy:0.7666666666666667\n",
      "Epoch 21\n",
      "TrainLoss:0.33352354168891907 TrainAccuracy:0.9705882352941176  TestLoss:0.49692872166633606 TestAccuracy:0.8\n",
      "Epoch 22\n",
      "TrainLoss:0.32049262523651123 TrainAccuracy:0.9621848739495799  TestLoss:0.4698992669582367 TestAccuracy:0.7833333333333333\n",
      "Epoch 23\n",
      "TrainLoss:0.30622345209121704 TrainAccuracy:0.9663865546218487  TestLoss:0.4707220196723938 TestAccuracy:0.8\n",
      "Epoch 24\n",
      "TrainLoss:0.3200153708457947 TrainAccuracy:0.9621848739495799  TestLoss:0.4930265247821808 TestAccuracy:0.75\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(pars,lr=1e-3) # Optimizer\n",
    "# tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(25):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    X_batches, y_batches = shuffle_and_batch(X_train, y_train, 4, 67)\n",
    "    for i in range(len(X_batches)):\n",
    "        preds = feedForward(X_batches[i])\n",
    "#         loss = criterion(preds,labelToOneHot(y_batches[i])) \n",
    "        loss = criterion(preds,y_batches[i].long())+ 0.65*sum(p.pow(2.0).sum() for p in pars)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Checking model on training set\n",
    "    train_preds = feedForward(X_train)\n",
    "    train_loss = criterion(train_preds, y_train.long())\n",
    "#     train_loss = criterion(train_preds,labelToOneHot(y_train))\n",
    "    train_preds = labelize(train_preds)\n",
    "    train_prediction_comparisons = (y_train == train_preds)\n",
    "    train_accuracy = float(train_prediction_comparisons.sum())/float(y_train.shape[0])\n",
    "    print('TrainLoss:{} TrainAccuracy:{}'.format(train_loss.item(), train_accuracy), end='  ')\n",
    "    \n",
    "\n",
    "    # Checking model on testing set\n",
    "    test_preds = feedForward(X_test)\n",
    "    test_loss = criterion(test_preds, y_test.long())\n",
    "#     test_loss = criterion(test_preds,labelToOneHot(y_test))\n",
    "    test_preds = labelize(test_preds)\n",
    "    test_prediction_comparisons = (y_test == test_preds)\n",
    "    test_accuracy = float(test_prediction_comparisons.sum())/float(y_test.shape[0])\n",
    "    print('TestLoss:{} TestAccuracy:{}'.format(test_loss.item(), test_accuracy))\n",
    "    \n",
    "#     tb.add_scalar('TrainLoss',train_loss, epoch)\n",
    "#     tb.add_scalar('TestLoss',test_loss, epoch)\n",
    "#     tb.add_scalar('TrainAccuracy', train_accuracy, epoch)\n",
    "#     tb.add_scalar('TestAccuracy', test_accuracy, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcOnFXPuN8Oo"
   },
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmatrix(target,preds):\n",
    "\n",
    "    di = {}\n",
    "    \n",
    "    count00 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==0.0 and j==0.0:\n",
    "            count00+=1\n",
    "    di['count00'] = count00\n",
    "        \n",
    "    \n",
    "    count11 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==1. and j==1.:\n",
    "            count11+=1\n",
    "    di['count11'] = count11\n",
    "\n",
    "    \n",
    "    count01 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==0. and j==1.:\n",
    "            count01+=1\n",
    "    di['count01'] = count01\n",
    "    \n",
    "    count10 = 0\n",
    "    for i,j in zip(target,preds):\n",
    "        if i==1. and j==0.:\n",
    "            count10+=1\n",
    "    di['count10'] = count10\n",
    "        \n",
    "    print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   0],\n",
       "       [  9, 110]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  6],\n",
       "       [ 9, 21]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, test_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AugSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xaug = pickle.load(open(f'X5040.pkl', 'rb'))\n",
    "yaug = pickle.load(open(f'y5040.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AugAccuracy:0.5240079365079365  "
     ]
    }
   ],
   "source": [
    "aug_preds = feedForward(Xaug)\n",
    "# aug_loss = criterion(aug_preds, labelToOneHot(yaug))\n",
    "aug_preds = labelize(aug_preds)\n",
    "aug_prediction_comparisons = (yaug == aug_preds)\n",
    "aug_accuracy = float(aug_prediction_comparisons.sum())/float(yaug.shape[0])\n",
    "print('AugAccuracy:{}'.format(aug_accuracy), end='  ')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1576,  944],\n",
       "       [1455, 1065]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yaug, aug_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5190640560189804"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yaug, aug_preds, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw = pickle.load(open(f'X5040_32_raw.pkl', 'rb'))\n",
    "yraw = pickle.load(open(f'y5040_32_raw.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RawAccuracy:0.6545522667665793  "
     ]
    }
   ],
   "source": [
    "raw_preds = feedForward(Xraw)\n",
    "# raw_loss = criterion(raw_preds, labelToOneHot(yraw))\n",
    "raw_preds = labelize(raw_preds)\n",
    "raw_prediction_comparisons = (yraw == raw_preds)\n",
    "raw_accuracy = float(raw_prediction_comparisons.sum())/float(yraw.shape[0])\n",
    "print('RawAccuracy:{}'.format(raw_accuracy), end='  ')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 148,    1],\n",
       "       [ 921, 1599]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yraw, raw_preds) #target on the vertical axis and preds on the horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7464475208134725"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yraw, raw_preds, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.Tensor([[1,2,3]])\n",
    "# b = nn.Linear(3,2)\n",
    "# c = nn.Dropout(p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([298, 3, 300, 300]), torch.Size([298]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pickle.load(open(f'X298.pkl', 'rb'))\n",
    "b = pickle.load(open(f'y298.pkl', 'rb'))\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "onezeroes = []\n",
    "for i in range(Xraw.shape[0]):\n",
    "    if yraw[i] == 1. and raw_preds[i] == 0.:\n",
    "        onezeroes.append(i)\n",
    "\n",
    "onezeroes = torch.Tensor(onezeroes).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "onezeroimages = Xraw[onezeroes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2669, 3, 32, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xraw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40aa5e9198>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(onezeroimages[5].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# tb = SummaryWriter()\n",
    "# grid = torchvision.utils.make_grid(onezeroimages[:10])\n",
    "# tb.add_image('ims',grid)\n",
    "# tb.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LeNet5.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
