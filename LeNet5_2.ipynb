{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "LeNet5.2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shouvikcirca/PCB_Defect_Detection/blob/master/LeNet5_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXw93V3KBuGL",
        "colab_type": "text"
      },
      "source": [
        "# LeNet5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x42ZnnA0BuGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import models, transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "\n",
        "nos = 7\n",
        "pars = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC2jsHuXB2q6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fc651b56-fb29-4d46-aa66-43abc8174cd9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoSCktJAB60c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.load('drive/My Drive/Copy of xtrain.npy')\n",
        "y = np.load('drive/My Drive/Copy of ytrain.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1zTL2ONB9Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eba69e60-8ed9-4de4-82aa-f413246f9a1a"
      },
      "source": [
        "X = torch.from_numpy(X)\n",
        "X = X.permute(0,3,1,2)\n",
        "y = torch.from_numpy(y)\n",
        "X.shape, y.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([298, 3, 300, 300]), torch.Size([298]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLB5FrOMBuGR",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUC_1EbfBuGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNormalized(X,s):\n",
        "    flattened_channels = X.reshape(3,-1)\n",
        "    channel_mean = flattened_channels.mean(dim = 1)\n",
        "    channel_stddev = flattened_channels.std(dim = 1)\n",
        "    preprocess2 = transforms.Compose([\n",
        "                      transforms.Normalize(channel_mean, channel_stddev)\n",
        "    ])\n",
        "\n",
        "\n",
        "    temptwo = torch.tensor([])\n",
        "    for i in range(X.shape[0]):\n",
        "      a = preprocess2(X[i])\n",
        "      temptwo = torch.cat([temptwo, a.reshape(1,3,s,s)])\n",
        "  \n",
        "    return temptwo\n",
        "\n",
        "\n",
        "def imageSetResize(newSize,X):\n",
        "    preprocess1 = transforms.Compose([\n",
        "                        transforms.ToPILImage(),\n",
        "                        transforms.Resize(newSize),\n",
        "                        transforms.ToTensor()])\n",
        "  \n",
        "    temp = torch.tensor([])\n",
        "    for i in range(X.shape[0]):\n",
        "        a = preprocess1(X[i])\n",
        "        temp = torch.cat([temp, a.reshape(1,3,newSize,newSize)])\n",
        "\n",
        "    return temp \n",
        "\n",
        "\n",
        "def splitTrainTest(X,y):\n",
        "    shuffled_indices = torch.randperm(X.shape[0])\n",
        "    ul = math.floor(0.8*X.shape[0])\n",
        "    train_indices = shuffled_indices[:ul]\n",
        "    test_indices = shuffled_indices[ul:]\n",
        "    # train_indices.shape[0] + test_indices.shape[0]\n",
        "    X_train = X[train_indices]\n",
        "    y_train = y[train_indices]  \n",
        "    X_test = X[test_indices]\n",
        "    y_test = y[test_indices]\n",
        "    print('y_train -> [0]:{} [1]:{}'.format((y_train == 0).sum().item(), (y_train == 1).sum().item()))\n",
        "    print('y_test -> [0]:{} [1]:{}'.format((y_test == 0).sum().item(), (y_test == 1).sum().item()))\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "def labelize(p):\n",
        "    labelized_preds = []\n",
        "    for i in p:\n",
        "        l = 0. if i[0]>i[1] else 1.\n",
        "        labelized_preds.append(l)\n",
        "\n",
        "    return torch.tensor(labelized_preds)\n",
        "\n",
        "\n",
        "\n",
        "def shuffle_and_batch(X,y,num,bs):\n",
        "    shuffled_indices = torch.randperm(X.shape[0])\n",
        "    newX = X[shuffled_indices]\n",
        "    newY = y[shuffled_indices]\n",
        "\n",
        "    X_batches = []\n",
        "    y_batches = []\n",
        "    for i in range(num):\n",
        "        X_batches.append(X[i*bs:(i+1)*bs])\n",
        "        y_batches.append(y_train[i*bs:(i+1)*bs])\n",
        "\n",
        "    return X_batches, y_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj6jcCXLBuGW",
        "colab_type": "text"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQy8vua7BuGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pars = []\n",
        "bims = torch.randn(7,3,32,32)\n",
        "\n",
        "#C1\n",
        "c1 = nn.Conv2d(3,6, kernel_size = 5)\n",
        "pars = pars + list(c1.parameters())\n",
        "\n",
        "#S2\n",
        "pool1 = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "#C3\n",
        "first_cons6_filterlist = []\n",
        "second_cons6_filterlist = []\n",
        "third_cons3_filterlist = []\n",
        "fourth_last1_filterlist = []\n",
        "for i in range(6):\n",
        "    first_cons6_filterlist.append(nn.Conv2d(3,1,kernel_size = 5))\n",
        "    pars = pars + list(first_cons6_filterlist[-1].parameters())\n",
        "    \n",
        "for i in range(6):\n",
        "    second_cons6_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
        "    pars = pars + list(second_cons6_filterlist[-1].parameters())\n",
        "    \n",
        "for i in range(3):\n",
        "    third_cons3_filterlist.append(nn.Conv2d(4,1,kernel_size = 5))\n",
        "    pars = pars + list(third_cons3_filterlist[-1].parameters())\n",
        "\n",
        "fourth_last1_filterlist = [nn.Conv2d(6,1,kernel_size = 5)]\n",
        "pars = pars + list(fourth_last1_filterlist[-1].parameters())\n",
        "\n",
        "#S4\n",
        "pool2 = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "#C5\n",
        "conv3 = nn.Conv2d(16, 120, kernel_size = 5)\n",
        "pars = pars + list(conv3.parameters())\n",
        "\n",
        "#F6\n",
        "ll1 = nn.Linear(120, 84)\n",
        "\n",
        "#F7\n",
        "ll2 = nn.Linear(84,2)\n",
        "pars = pars + list(ll1.parameters()) + list(ll2.parameters())\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(pars,lr=1e-4) # Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # Loss Function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5QbXFhbBuGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayDetails(lone = None, ltwo=None):\n",
        "    if lone is not None:\n",
        "        a = lone\n",
        "        print('--------')\n",
        "        for i in a[0]:\n",
        "            print(i)\n",
        "        print('--------')\n",
        "        for i in a[1]:\n",
        "            print(i)\n",
        "        print('-------')\n",
        "        for i in a[2]:\n",
        "            print(i)\n",
        "        print('-------')\n",
        "        for i in a[3]:\n",
        "            print(i)\n",
        "    if ltwo is not None:\n",
        "        a = ltwo\n",
        "        for i in a:\n",
        "            print('-----')\n",
        "            for j in i:\n",
        "                print(j.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2xDzuPRBuGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displayDetails(lone = [first_cons6_filterlist,second_cons6_filterlist,third_cons3_filterlist,fourth_last1_filterlist])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-jMzvZ1BuGh",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC6H9PuXBuGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "308bc25b-2f70-45da-f341-3982271d9399"
      },
      "source": [
        "resized_imageset = imageSetResize(32, X.float())\n",
        "normalized_imageset = getNormalized(resized_imageset.float(),32)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train -> [0]:123 [1]:115\n",
            "y_test -> [0]:26 [1]:34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5d3IZAnDsfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9fa052f0-5032-4007-dcda-16c0620cad8f"
      },
      "source": [
        "X_train, y_train, X_test, y_test = splitTrainTest(resized_imageset, y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train -> [0]:118 [1]:120\n",
            "y_test -> [0]:31 [1]:29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpmIw5uaBuGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ef(li, c1_out):\n",
        "    return torch.index_select(c1_out, 1, torch.tensor(li))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdR1kcwSBuGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feedForward(X):\n",
        "    \n",
        "    global c1\n",
        "    global first_cons6_filterlist\n",
        "    global second_cons6_filterlist\n",
        "    global third_cons3_filterlist\n",
        "    global fourth_last1_filterlist\n",
        "    nos = X.shape[0]\n",
        "    c1_out = c1(X)\n",
        "    out = torch.tanh(pool1(c1_out))\n",
        "    lione = [ef([0,1,2],out),ef([1,2,3],out), ef([2,3,4],out), ef([3,4,5],out), ef([0,4,5],out),ef([0,1,5],out)]\n",
        "    litwo = [ef([0,1,2,3],out),ef([1,2,3,4],out), ef([2,3,4,5],out), ef([0,3,4,5],out), ef([0,1,4,5],out),ef([0,1,2,5],out)]\n",
        "    lithree = [ef([0,1,3,4],out),ef([1,2,4,5],out), ef([0,2,3,5],out)]\n",
        "    lifour = [ef([0,1,2,3,4,5],out)]\n",
        "    feature_maps1 = []\n",
        "    feature_maps2 = []\n",
        "    feature_maps3 = []\n",
        "    feature_maps4 = []\n",
        "    for i in range(6):\n",
        "        feature_maps1.append(first_cons6_filterlist[i](lione[i]))\n",
        "    for i in range(6):\n",
        "        feature_maps2.append(second_cons6_filterlist[i](litwo[i]))\n",
        "    for i in range(3):\n",
        "        feature_maps3.append(third_cons3_filterlist[i](lithree[i]))\n",
        "    for i in range(1):\n",
        "        feature_maps4.append(fourth_last1_filterlist[i](lifour[i]))\n",
        "    fms = []\n",
        "    fms.extend(feature_maps1)\n",
        "    fms.extend(feature_maps2)\n",
        "    fms.extend(feature_maps3)\n",
        "    fms.extend(feature_maps4)\n",
        "    tfms = torch.Tensor([])\n",
        "    for i in fms:\n",
        "        tfms = torch.cat([tfms, i], dim=1)\n",
        "    c2_out = torch.tanh(pool2(tfms))\n",
        "    c3_out = conv3(c2_out)\n",
        "    c3_out = c3_out.reshape(nos,120)\n",
        "    ll1_out = torch.tanh(ll1(c3_out))\n",
        "    ll2_out = ll2(ll1_out)\n",
        "    preds = nn.Softmax(dim=1)(ll2_out)\n",
        "    \n",
        "    return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDMvGyz7BuGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45c746a5-ba45-4ccc-9c60-1c108140b6cf"
      },
      "source": [
        "for epoch in range(30):\n",
        "    print('Epoch {}'.format(epoch))\n",
        "    X_batches, y_batches = shuffle_and_batch(X_train, y_train, 4, 67)\n",
        "    for i in range(len(X_batches)):\n",
        "        preds = feedForward(X_batches[i])\n",
        "        loss = criterion(preds,y_batches[i].long())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward(retain_graph = True)\n",
        "        optimizer.step()\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Checking model on training set\n",
        "    train_preds = feedForward(X_train)\n",
        "    train_loss = criterion(train_preds, y_train.long())\n",
        "    train_preds = labelize(train_preds)\n",
        "    train_prediction_comparisons = (y_train == train_preds)\n",
        "    train_accuracy = float(train_prediction_comparisons.sum())/float(y_train.shape[0])\n",
        "    print('Training Loss:{}\\tTraining Accuracy:{}'.format(train_loss.item(), train_accuracy), end='  ')\n",
        "  \n",
        "    # Checking model on testing set\n",
        "    test_preds = feedForward(X_test)\n",
        "    test_loss = criterion(test_preds, y_test.long())\n",
        "    test_preds = labelize(test_preds)\n",
        "    test_prediction_comparisons = (y_test == test_preds)\n",
        "    test_accuracy = float(test_prediction_comparisons.sum())/float(y_test.shape[0])\n",
        "    print('Testing Loss:{}\\tTesting Accuracy:{}'.format(test_loss.item(), test_accuracy))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Training Loss:0.6039713621139526\tTraining Accuracy:0.7142857142857143  Testing Loss:0.6402027010917664\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 1\n",
            "Training Loss:0.6013367176055908\tTraining Accuracy:0.7142857142857143  Testing Loss:0.6371092200279236\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 2\n",
            "Training Loss:0.5986915230751038\tTraining Accuracy:0.7142857142857143  Testing Loss:0.6340157985687256\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 3\n",
            "Training Loss:0.5960384607315063\tTraining Accuracy:0.7142857142857143  Testing Loss:0.6309395432472229\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 4\n",
            "Training Loss:0.5933802723884583\tTraining Accuracy:0.7142857142857143  Testing Loss:0.6278982758522034\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 5\n",
            "Training Loss:0.5907199382781982\tTraining Accuracy:0.7226890756302521  Testing Loss:0.6249076724052429\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 6\n",
            "Training Loss:0.5880603790283203\tTraining Accuracy:0.7226890756302521  Testing Loss:0.6219817399978638\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 7\n",
            "Training Loss:0.5854039788246155\tTraining Accuracy:0.726890756302521  Testing Loss:0.6191317439079285\tTesting Accuracy:0.6833333333333333\n",
            "Epoch 8\n",
            "Training Loss:0.5827536582946777\tTraining Accuracy:0.7310924369747899  Testing Loss:0.6163656115531921\tTesting Accuracy:0.7\n",
            "Epoch 9\n",
            "Training Loss:0.5801110863685608\tTraining Accuracy:0.7310924369747899  Testing Loss:0.6136885285377502\tTesting Accuracy:0.7\n",
            "Epoch 10\n",
            "Training Loss:0.5774796009063721\tTraining Accuracy:0.7310924369747899  Testing Loss:0.6111029386520386\tTesting Accuracy:0.7\n",
            "Epoch 11\n",
            "Training Loss:0.5748605728149414\tTraining Accuracy:0.7394957983193278  Testing Loss:0.6086084842681885\tTesting Accuracy:0.7\n",
            "Epoch 12\n",
            "Training Loss:0.5722571015357971\tTraining Accuracy:0.7394957983193278  Testing Loss:0.6062037944793701\tTesting Accuracy:0.7\n",
            "Epoch 13\n",
            "Training Loss:0.569672167301178\tTraining Accuracy:0.7478991596638656  Testing Loss:0.6038864254951477\tTesting Accuracy:0.7\n",
            "Epoch 14\n",
            "Training Loss:0.5671083927154541\tTraining Accuracy:0.7478991596638656  Testing Loss:0.6016532182693481\tTesting Accuracy:0.7\n",
            "Epoch 15\n",
            "Training Loss:0.564569890499115\tTraining Accuracy:0.7605042016806722  Testing Loss:0.5995010137557983\tTesting Accuracy:0.7\n",
            "Epoch 16\n",
            "Training Loss:0.5620604157447815\tTraining Accuracy:0.7689075630252101  Testing Loss:0.5974271297454834\tTesting Accuracy:0.7\n",
            "Epoch 17\n",
            "Training Loss:0.5595839619636536\tTraining Accuracy:0.7689075630252101  Testing Loss:0.5954294800758362\tTesting Accuracy:0.7\n",
            "Epoch 18\n",
            "Training Loss:0.5571455955505371\tTraining Accuracy:0.7689075630252101  Testing Loss:0.593506395816803\tTesting Accuracy:0.7\n",
            "Epoch 19\n",
            "Training Loss:0.5547498464584351\tTraining Accuracy:0.773109243697479  Testing Loss:0.5916572213172913\tTesting Accuracy:0.7\n",
            "Epoch 20\n",
            "Training Loss:0.5524013638496399\tTraining Accuracy:0.7773109243697479  Testing Loss:0.5898816585540771\tTesting Accuracy:0.7\n",
            "Epoch 21\n",
            "Training Loss:0.5501058101654053\tTraining Accuracy:0.773109243697479  Testing Loss:0.5881804823875427\tTesting Accuracy:0.7\n",
            "Epoch 22\n",
            "Training Loss:0.547866940498352\tTraining Accuracy:0.7773109243697479  Testing Loss:0.5865539312362671\tTesting Accuracy:0.7\n",
            "Epoch 23\n",
            "Training Loss:0.5456886887550354\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5850032567977905\tTesting Accuracy:0.7\n",
            "Epoch 24\n",
            "Training Loss:0.543574869632721\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5835291147232056\tTesting Accuracy:0.7166666666666667\n",
            "Epoch 25\n",
            "Training Loss:0.5415284037590027\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5821321606636047\tTesting Accuracy:0.7166666666666667\n",
            "Epoch 26\n",
            "Training Loss:0.5395509600639343\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5808125734329224\tTesting Accuracy:0.7\n",
            "Epoch 27\n",
            "Training Loss:0.5376442074775696\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5795701742172241\tTesting Accuracy:0.7166666666666667\n",
            "Epoch 28\n",
            "Training Loss:0.535807728767395\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5784035921096802\tTesting Accuracy:0.7166666666666667\n",
            "Epoch 29\n",
            "Training Loss:0.534042477607727\tTraining Accuracy:0.7815126050420168  Testing Loss:0.5773118734359741\tTesting Accuracy:0.7333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcOnFXPuN8Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJgtiIk8N8RW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODpPQEEN8Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}